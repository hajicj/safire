[_info]
name='test_training_config'

[_loader]
_class=safire.data.loaders.MultimodalShardedDatasetLoader
root='test-data/'
name='test-data'

[_builder]
_import=safire.datasets.dataset.Dataset
save=True
save_every=False
savename=_loader.pipeline_name(_info.name)
log_blocks=False
log_saving=False

[_assembly]
_1_=icorp
_tanh_=tanh[_1_]
_2_=serializer[_tanh_]
_3_=sftrans[_2_]
_4_=trained_serializer[_3_]

[_persistence]
loader=_loader
_4_=.img.DA-200

[sftrans]
_class=safire.learning.interfaces.safire_transformer.SafireTransformer
_dependencies=run_handle,model_handles,learner
_access_deps=run_handle:sftrans.run_handle
_import=safire.datasets.dataset.Dataset
run_handle=run_handle
setup_handles=model_handles
dataset=Dataset(_2_)
learner=learner
dense_throughput=False

[run_handle]
_dependencies=model_handles
_exec=model_handles['run']

[model_handles]
_import=safire.learning.models.denoising_autoencoder.DenoisingAutoencoder,theano
_init=DenoisingAutoencoder.setup
data=Dataset(_2_)
n_out=200
activation=theano.tensor.nnet.sigmoid
backward_activation=theano.tensor.tanh
reconstruction='mse'
heavy_debug=False

[learner]
_class=safire.learning.learners.base_sgd_learner.BaseSGDLearner
n_epochs=5
b_size=1
learning_rate=0.13
validation_frequency=4
plot_transformation=False

[serializer]
_import=safire.data.sharded_corpus.ShardedCorpus
_class=safire.data.serializer.Serializer
corpus=_1_
serializer_class=ShardedCorpus
fname=_loader.pipeline_serialization_target('untrained_serializer')
overwrite=False

[trained_serializer]
_import=safire.data.sharded_corpus.ShardedCorpus
_class=safire.data.serializer.Serializer
corpus=_3_
serializer_class=ShardedCorpus
fname=_loader.pipeline_serialization_target('trained_serializer')
overwrite=False

[tanh]
_import=numpy
_class=safire.utils.transformers.GeneralFunctionTransform
fn=numpy.tanh
multiplicative_coef=0.4

[icorp]
_class=safire.data.imagenetcorpus.ImagenetCorpus
input=os.path.join(_loader.root, _loader.layout.image_vectors)
delimiter=';'
dim=4096


